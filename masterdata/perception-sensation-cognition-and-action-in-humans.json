{
    "protocolSection": {
        "identificationModule": {
            "nctId": "NCT03407066",
            "orgStudyIdInfo": {
                "id": "180046"
            },
            "secondaryIdInfos": [
                {
                    "id": "18-EI-0046"
                }
            ],
            "organization": {
                "fullName": "National Institutes of Health Clinical Center (CC)",
                "class": "NIH"
            },
            "briefTitle": "Perception, Sensation, Cognition and Action in Humans",
            "officialTitle": "Perception, Sensation, Cognition and Action in Humans",
            "therapeuticArea": [
                "Other"
            ],
            "study": "perception-sensation-cognition-and-action-in-humans"
        },
        "statusModule": {
            "statusVerifiedDate": "2023-10-16",
            "overallStatus": "RECRUITING",
            "expandedAccessInfo": {
                "hasExpandedAccess": false
            },
            "startDateStruct": {
                "date": "2019-03-26",
                "type": "ACTUAL"
            },
            "primaryCompletionDateStruct": {
                "date": "2025-12-31",
                "type": "ESTIMATED"
            },
            "completionDateStruct": {
                "date": "2025-12-31",
                "type": "ESTIMATED"
            },
            "studyFirstSubmitDate": "2018-01-20",
            "studyFirstSubmitQcDate": "2018-01-20",
            "studyFirstPostDateStruct": {
                "date": "2018-01-23",
                "type": "ACTUAL"
            },
            "lastUpdateSubmitDate": "2023-10-17",
            "lastUpdatePostDateStruct": {
                "date": "2023-10-18",
                "type": "ACTUAL"
            }
        },
        "sponsorCollaboratorsModule": {
            "responsibleParty": {
                "type": "SPONSOR"
            },
            "leadSponsor": {
                "name": "National Eye Institute (NEI)",
                "class": "NIH"
            }
        },
        "oversightModule": {
            "isFdaRegulatedDrug": false,
            "isFdaRegulatedDevice": false
        },
        "descriptionModule": {
            "briefSummary": "Background:\n\nWhen people see and hear, the brain changes signals from the eyes and ears into perceptions and thoughts. No one fully understands how this happens. Researchers want to explore how healthy brains process sights and sounds.\n\nObjectives:\n\nTo explore how people understand what they see and hear when the brain processes sights and sounds.\n\nEligibility:\n\nAdults ages 18-65 who have at least 20/40 vision in at least one eye and do not use a hearing aid.\n\nDesign:\n\nSome participants will take tests online anonymously. They will do computer tasks related to colors and behavior.\n\nIn-person participants will be screened with medical history and physical exam. They will complete questionnaires and vision and hearing tests.\n\nParticipants will plan how many testing sessions they will have and when. Sessions last 2-5 hours. They may include:\n\nMagnetic Resonance Imaging: Magnets and radio waves to take pictures of the brain. Participants will lie on a table that slides in and out of a tube. They will do a task during the scan.\n\nMagnetoencephalography: Records magnetic field changes from brain activity. Participants will sit or lie down. A cone will be lowered onto their head. They may do a task during the test.\n\nElectromyography: Electrodes attached to the skin will measure the electrical activity of muscles.\n\nElectroencephalogram: Electrodes on the scalp will record brain waves.\n\nElectrocardiography: Electrodes on the chest will record heart electrical activity.\n\nTests of memory, attention, thinking, vision, and hearing.\n\nEye Tracking: Cameras will follow participants eye movements. They may wear a cap with infrared cameras in front of their eyes.\n\nDuring the sessions, participants vital signs may be monitored.",
            "detailedDescription": "Objective:\n\nThe experiments covered by this protocol aim to uncover basic knowledge about the normal brain mechanisms that give rise to perception and cognition. The protocol encompasses sub-studies in healthy volunteers ( participants ) to uncover behaviors and their physiological basis.\n\nThe protocol includes only non- or minimally-invasive techniques with minimal risk, including psychophysics, functional magnetic resonance imaging (fMRI), magnetoencephalography (MEG), genetic sequencing, and on-line tests using Amazon s Mechanical Turk (MTurk). The overarching goal of the research is to obtain new knowledge in the organization and operation of cortical circuits involved in visual and auditory perception. The protocol covers six specific inter-related aims, with specific sub-studies:\n\n1. Neurophysiological Mechanisms for Color\n2. Object-Color Associations (Color Memory)\n3. Connectivity of Functionally-Defined Regions\n4. Homologies between Monkeys and Humans\n5. Functional Organization of Sound Perception and Visual-Auditory Integration\n6. Multi-stability in Color Perception\n\nStudy Population:\n\nNormal volunteer participants aged 18-65, who are in good general health and have normal or corrected-to-normal vision will be recruited from the local community and studied under this minimal risk protocol. We plan to recruit up to 200 in-person participants and up to 10,000 on-line volunteers.\n\nDesign:\n\nIn some sub-studies, the same subject will be asked to participate in tasks involving fMRI, MEG and psychophysics, and multiple sessions of each, so that we can control for individual differences in relating the outcomes of each experimental technique. In other sub-studies, participation in multiple tasks will not be required. The extent of the participant involvement, and what they will be asked to do, will be clearly disclosed during consent, as indicated in the consent documents. Brain activity of healthy human volunteers will be monitored by fMRI and/or MEG. Anatomical MRI will be collected in some subjects to allow better localization of brain dynamics. Behavioral tests will be conducted using standard psychophysical approaches, involving presentation of visual and/or auditory stimuli while eye-movements are monitored using non-invasive eye tracking (such as with an infra-red camera directed at the participant s eyes). Subjects will be shown simple visual stimuli such as blobs, stripes and spirals in assorted colors, moving dots, checkerboards, and every-day images and video clips, such as of fruit rolling on a table cloth, faces, and scenery recorded in a car. Auditory stimuli will include every-day sounds such as birds singing, conversation, whispering, footsteps, car engines, and animal vocalizations, presented within normal sound limits (60- 90 dB). We will not use provocative or sexually explicit images, clips or sounds. During fMRI and MEG sessions, subjects will be asked to free view, passively fixate, or engage in an attentional task during fixation, such as reporting with an eye movement or button press occasions when two images of the same category are presented sequentially.\n\nOutcome Measures:\n\nPerformance on behavioral tasks and brain activity (fMRI and MEG) will be combined to yield information about the neural correlates and processes underlying different aspects of the human neural visual processing stream including color perception, attention, visual discrimination and object/face/place recognition.\n\ni. MRI: to analyze measures such as the anatomical structures of the brain (using structural MRI); amplitude of the blood-oxygenation-level-dependent (BOLD) signal \\& using fMRI).\n\nii. MEG: to quantify measures such as power spectrum, event- or task-related potentials, synchronization/desynchronization, and coherence between sensors or sources located close to the brain areas of interest.\n\niii. Behavioral measures: to quantify measures such as hit rate, reaction times, thresholds, similarity judgments, associations, naming (such as names for color stimuli and sounds) and eye movements.\n\nWe may measure autonomic data during the course of the experiment (such as heart rate, respiration, end-tidal CO2, skin conductance), which will be correlated with the outcome measures."
        },
        "conditionsModule": {
            "conditions": [
                "Normal Physiology"
            ],
            "keywords": [
                "Magnetic Resonance Imaging (MRI)",
                "MEG",
                "Color Vision",
                "Neuroimaging",
                "Natural History"
            ]
        },
        "designModule": {
            "studyType": "OBSERVATIONAL",
            "designInfo": {
                "observationalModel": "COHORT",
                "timePerspective": "PROSPECTIVE"
            },
            "enrollmentInfo": {
                "count": 10200,
                "type": "ESTIMATED"
            }
        },
        "armsInterventionsModule": {
            "armGroups": [
                {
                    "label": "In-person",
                    "description": "200 in-person healthy volunteers"
                },
                {
                    "label": "On-line",
                    "description": "10,000 on-line healthy volunteers"
                }
            ]
        },
        "outcomesModule": {
            "primaryOutcomes": [
                {
                    "measure": "MRI",
                    "description": "We will analyze the anatomical structures of the brain (structural MRI or DTI); amplitude of the BOLD signal (fMRI).",
                    "timeFrame": "duration of the study"
                },
                {
                    "measure": "MEG",
                    "description": "We will quantify measures such as power spectrum, event- of task-related potentials, synchronization/de-synchronization and coherence between sensors or sources located close to the brain areas of interest.",
                    "timeFrame": "duration of the study"
                },
                {
                    "measure": "Behavioral Measures",
                    "description": "We will quantify measures such as hit rate, reaction times, detection thresholds, eye movement patterns, color, shape and sound judgement. We may measure autonomic data during the course of the sub-study (such as heart rate, respiration, end-tidal CO2, skin conductance), which will be correlated to the outcome measures.",
                    "timeFrame": "duration of the study"
                }
            ]
        },
        "eligibilityModule": {
            "eligibilityCriteria": "* INCLUSION CRITERIA FOR ALL PARTICIPANTS:\n\nA subject can be included in this study if he/she:\n\n* is in good general health;\n* is between 18 and 65 years old;\n* is capable of understanding the procedures and requirements of this study;\n* is willing and able to provide his/her own informed consent;\n\nADDITIONAL INCLUSION CRITERIA FOR IN-LAB PARTICIPANTS:\n\n* has visual acuity of 20/40 in at least one eye (corrected with contact lenses is okay);\n* has no hearing impairment requiring a hearing aid.\n\nEXCLUSION CRITIERA FOR IN-LAB PARTICIPANTS:\n\nA participant is not eligible for participation in the in-lab portion of this study if any of the following exclusion criteria are present, as self-reported by the prospective participant or determined during clinical testing following consent:\n\n* Participant has serious vision or hearing problems; for some sub-studies focused on color vision, subjects who are colorblind will also be excluded;\n* Participants without consent capacity will not be enrolled;\n* Participant has a neurological disorder (examples include, but are not limited to: epilepsy, schizophrenia, Alzheimer s Disease, Parkinson s Disease, multiple sclerosis) or a psychiatric disorder (examples include, but are not limited to: clinical anxiety, depression, attention deficit hyperactivity disorder (ADHD), schizophrenia);\n* Participant has had a serious head injury or has a history of brain surgery. Head injury is defined as an injury to the brain from some external force resulting in loss of consciousness of 30 minutes or more;\n* Participant has psychoactive drug or alcohol abuse or dependence in the past three months, as determined by the Drug Abuse Screening Test (DAST), except nicotine and caffeine. A score of 6 or greater on the DAST will be considered exclusionary. The effects of nicotine and caffeine in neuroimaging are attenuated if participants do not smoke or consume caffeine 2-3 hours before the scan session; Over-the-counter medication/herbals will not be a criterion for exclusion;\n* Participant is an NEI employee within the Sensation, Cognition and Action section.\n\nADDITIONAL EXCLUSION CRITERIA FOR MRI SUB-STUDIES:\n\nContraindication to MR scanning include the following: pregnancy; metallic tattoos or metallic eyeliner; claustrophobia; inability to lie still on their back for \\~2 hours; implanted cardiac pacemaker or auto-defibrillator; surgical aneurysm clips; implanted neural stimulator; artificial heart valves or pumps; metal fragments in cranial cavity, body or eyes (e.g., history as a metal worker); nitroglycerin patch (foil backer); cochlear implants (tubes are okay); weight \\> 450 lbs; metal rods, plates, screws in body; shrapnel or bullet wound; intrauterine device (IUD) not approved on mrisafety.com (most IUDs are okay); vestibular or inner ear abnormality such as Meniere s disease; metallic braces; hair extensions attached with metallic wires; transdermal patches; movement disorders; dental implants; consumed of nicotine or caffeine in the two hours prior to the experimental session. Subjects may participate in this study, but will not be allowed to have a 7.0 T MRI scan if they have metallic dental crowns or a bridge.\n\nADDITIONAL EXCLUSION CRITERIA FOR OFF-SITE PARTICIPANTS:\n\nOff-site participation is limited to participants with XY chromosomes until the genetic sequencing capability changes.\n\nEXCLUSION CRITERIA FOR ON-LINE PARTICIPANTS:\n\nSubjects may not participate in the on-line portion of the study if they:\n\n* Do not have access to compatible equipment. For example, smartphone screens are too small to be used. Amazon MTurk will outline which devices may be used.\n* Are unwilling to allow permission for JavaScript to run on the site and disable any script blockers.\n* Are unwilling to agree to Amazon MTurk's terms and conditions.",
            "healthyVolunteers": true,
            "sex": "ALL",
            "minimumAge": "18 Years",
            "maximumAge": "65 Years",
            "stdAges": [
                "ADULT",
                "OLDER_ADULT"
            ],
            "studyPopulation": "For in-lab testing, two hundred subjects (200) will be recruited from a healthy adult population and are expected to represent a broad cross-section of the population. For on-line testing, we anticipate up to 10,000 subjects will be recruited.",
            "samplingMethod": "NON_PROBABILITY_SAMPLE"
        },
        "contactsLocationsModule": {
            "centralContacts": [
                {
                    "name": "Marianne F Duyck, Ph.D.",
                    "role": "CONTACT",
                    "phone": "(301) 402-4956",
                    "email": "marianne.duyck@nih.gov"
                },
                {
                    "name": "Bevil Conway, Ph.D.",
                    "role": "CONTACT",
                    "phone": "(301) 594-3238",
                    "email": "bevil.conway@nih.gov"
                }
            ],
            "overallOfficials": [
                {
                    "name": "Bevil Conway, Ph.D.",
                    "affiliation": "National Eye Institute (NEI)",
                    "role": "PRINCIPAL_INVESTIGATOR"
                }
            ],
            "locations": [
                {
                    "facility": "National Eye Institute (NEI)",
                    "status": "RECRUITING",
                    "city": "Bethesda",
                    "state": "Maryland",
                    "zip": "20892",
                    "country": "United States",
                    "geoPoint": {
                        "lat": 38.98067,
                        "lon": -77.10026
                    }
                },
                {
                    "facility": "National Institutes of Health Clinical Center",
                    "status": "RECRUITING",
                    "city": "Bethesda",
                    "state": "Maryland",
                    "zip": "20892",
                    "country": "United States",
                    "contacts": [
                        {
                            "name": "For more information at the NIH Clinical Center contact Office of Patient Recruitment (OPR)",
                            "role": "CONTACT",
                            "phone": "800-411-1222",
                            "phoneExt": "TTY8664111010",
                            "email": "prpl@cc.nih.gov"
                        }
                    ],
                    "geoPoint": {
                        "lat": 38.98067,
                        "lon": -77.10026
                    }
                }
            ]
        },
        "referencesModule": {
            "seeAlsoLinks": [
                {
                    "label": "NIH Clinical Center Detailed Web Page",
                    "url": "https://clinicalstudies.info.nih.gov/cgi/detail.cgi?A_2018-EI-0046.html"
                }
            ]
        },
        "ipdSharingStatementModule": {
            "ipdSharing": "NO"
        }
    },
    "derivedSection": {
        "miscInfoModule": {
            "versionHolder": "2024-07-30"
        }
    },
    "hasResults": false
}