{
    "protocolSection": {
        "identificationModule": {
            "nctId": "NCT05988515",
            "orgStudyIdInfo": {
                "id": "22-426b"
            },
            "secondaryIdInfos": [
                {
                    "id": "1R01DC020959-01",
                    "type": "NIH",
                    "link": "https://reporter.nih.gov/quickSearch/1R01DC020959-01"
                }
            ],
            "organization": {
                "fullName": "Syracuse University",
                "class": "OTHER"
            },
            "briefTitle": "AI-Assisted Treatment for Residual Speech Sound Disorders",
            "officialTitle": "AI-Assisted Treatment for Residual Speech Sound Disorders",
            "therapeuticArea": [
                "Other"
            ],
            "study": "ai-assisted-treatment-for-residual-speech-sound-disorders"
        },
        "statusModule": {
            "statusVerifiedDate": "2024-04",
            "overallStatus": "RECRUITING",
            "expandedAccessInfo": {
                "hasExpandedAccess": false
            },
            "startDateStruct": {
                "date": "2024-03-12",
                "type": "ACTUAL"
            },
            "primaryCompletionDateStruct": {
                "date": "2027-11",
                "type": "ESTIMATED"
            },
            "completionDateStruct": {
                "date": "2027-12",
                "type": "ESTIMATED"
            },
            "studyFirstSubmitDate": "2023-08-04",
            "studyFirstSubmitQcDate": "2023-08-04",
            "studyFirstPostDateStruct": {
                "date": "2023-08-14",
                "type": "ACTUAL"
            },
            "lastUpdateSubmitDate": "2024-04-23",
            "lastUpdatePostDateStruct": {
                "date": "2024-04-24",
                "type": "ACTUAL"
            }
        },
        "sponsorCollaboratorsModule": {
            "responsibleParty": {
                "type": "SPONSOR"
            },
            "leadSponsor": {
                "name": "Syracuse University",
                "class": "OTHER"
            },
            "collaborators": [
                {
                    "name": "National Institutes of Health (NIH)",
                    "class": "NIH"
                },
                {
                    "name": "State University of New York - Upstate Medical University",
                    "class": "OTHER"
                },
                {
                    "name": "National Institute on Deafness and Other Communication Disorders (NIDCD)",
                    "class": "NIH"
                }
            ]
        },
        "oversightModule": {
            "oversightHasDmc": true,
            "isFdaRegulatedDrug": false,
            "isFdaRegulatedDevice": false
        },
        "descriptionModule": {
            "briefSummary": "The goal of this randomized-controlled trial is to determine how artificial intelligence-assisted home practice may enhance speech learning of the \"r\" sound in school-age children with residual speech sound disorders. All child participants will receive 1 speech lesson per week, via telepractice, for 5 weeks with a human speech-language clinician. Some participants will receive 3 speech sessions per week with an Artificial Intelligence (AI)-clinician during the same 5 weeks as the human clinician sessions (CONCURRENT treatment order group), whereas others will receive 3 speech sessions per week with an AI-clinician after the human clinician sessions end (SEQUENTIAL treatment order group.",
            "detailedDescription": "Artificial Intelligence-assisted treatment that detects mispronunciations within an evidence-based motor learning framework could increase access to sufficiently intense, efficacious treatment despite provider shortages. A successful Artificial intelligencesystem that can predict the clinical gold standard of trained listeners' perceptions could not only improve access to clinical care but also mitigate known confounds to accurate clinical feedback, including clinical experience and drift due to increasing familiarity between the speaker and listener. The Artificial intelligence tool used in this study includes a speech classifier trained to predict clinician judgment of American English \"r\" that is integrated into an existing evidence-based treatment software called Speech Motor Chaining."
        },
        "conditionsModule": {
            "conditions": [
                "Speech Sound Disorder"
            ]
        },
        "designModule": {
            "studyType": "INTERVENTIONAL",
            "phases": [
                "NA"
            ],
            "designInfo": {
                "allocation": "RANDOMIZED",
                "interventionModel": "PARALLEL",
                "interventionModelDescription": "Participants will be randomized across two conditions, CONCURRENT and SEQUENTIAL\n\nParticipants randomized to receive CONCURRENT treatment will receive speech lessons with a human clinician once per week for five weeks, along with 3 sessions per week of parent-supervised Chaining-AI (15 Chaining-AI sessions). Therefore, clinician-led and Chaining-AI are completed concurrently.\n\nParticipants randomized to receive SEQUENTIAL treatment will receive speech lessons with a human clinician once per week for five weeks, followed by three sessions per week of parent-supervised Chaining-AI for the NEXT five weeks. Therefore, clinician-led and Chaining-AI are completed sequentially.",
                "primaryPurpose": "TREATMENT",
                "maskingInfo": {
                    "masking": "SINGLE",
                    "maskingDescription": "All perceptual ratings will be obtained from trained listeners who are blinded to treatment group and to timepoint. Binary rating of accuracy of the \"r\" sound (i.e., judgments of correct or incorrect) will be obtained from three listeners per token.",
                    "whoMasked": [
                        "OUTCOMES_ASSESSOR"
                    ]
                }
            },
            "enrollmentInfo": {
                "count": 26,
                "type": "ESTIMATED"
            }
        },
        "armsInterventionsModule": {
            "armGroups": [
                {
                    "label": "CONCURRENT treatment order",
                    "type": "EXPERIMENTAL",
                    "description": "* 5 speech lessons with a human speech-language clinician: 1 time per week for 5 weeks.\n* 15 speech lessons with an AI clinician (supervised by the caregiver), 3 times per week DURING the same 5 weeks as the human clinician sessions.",
                    "interventionNames": [
                        "Behavioral: Speech-Language Pathologist-led Speech Motor Chaining",
                        "Behavioral: Artificial Intelligence-led Speech Motor Chaining (CHAINING-AI)"
                    ]
                },
                {
                    "label": "SEQUENTIAL treatment order",
                    "type": "EXPERIMENTAL",
                    "description": "* 5 speech lessons with a human speech-language clinician: 1 time per week for 5 weeks.\n* 15 speech lessons with an AI clinician (supervised by the caregiver), 3 times per week for the 5 weeks AFTER the human clinician sessions end.",
                    "interventionNames": [
                        "Behavioral: Speech-Language Pathologist-led Speech Motor Chaining",
                        "Behavioral: Artificial Intelligence-led Speech Motor Chaining (CHAINING-AI)"
                    ]
                }
            ],
            "interventions": [
                {
                    "type": "BEHAVIORAL",
                    "name": "Speech-Language Pathologist-led Speech Motor Chaining",
                    "description": "Sessions begin with Pre-practice to elicit the /r/ sound. During Structured Practice, the same utterance is practiced several times in a row (with systematic increases in difficulty based on performance). Our web-based software manipulates the principles of motor learning, including feedback prompts for the clinician, the complexity of the utterance, and the variability in the practice trial; the software will analyze the clinician's rating to increase the difficulty of practice when the child is more accurate. Randomized Practice will also be guided by the software and includes all linguistic levels that were produced correctly during Structured Practice, with items presented in random order. A trained speech-language pathologist is involved in all practice trials to provide feedback throughout the session.",
                    "armGroupLabels": [
                        "CONCURRENT treatment order",
                        "SEQUENTIAL treatment order"
                    ]
                },
                {
                    "type": "BEHAVIORAL",
                    "name": "Artificial Intelligence-led Speech Motor Chaining (CHAINING-AI)",
                    "description": "Sessions include Structured Practice and Randomized Practice using our web-based software with an Artificial Intelligence clinician to address the /r/ sound. Within a practice session, participants speak into a microphone, and the audio file is sent to a server to be analyzed by a classifier, which returns a binary accurate/inaccurate rating of productions in a fashion similar to SLP judgment. Our web-based software manipulates the principles of motor learning, including feedback prompts, the complexity of the utterance, and the variability in the practice trial. The software will analyze the child's accuracy as determined by the classifier to increase the difficulty of practice when the child is more accurate.",
                    "armGroupLabels": [
                        "CONCURRENT treatment order",
                        "SEQUENTIAL treatment order"
                    ]
                }
            ]
        },
        "outcomesModule": {
            "primaryOutcomes": [
                {
                    "measure": "Change in percent correct for the /\u0279/ sound in untreated words, rated by blinded listeners.",
                    "description": "To assess generalization of treatment gains to untreated words, participants will read a word list eliciting /\u0279/. Stimuli in each list will be presented individually in randomized order. Individual words will be isolated from the audio record of each word probe and presented in randomized order for perceptual rating by trained listeners who are blind to treatment condition and time point (but will see the written representation of each target word). We will use the change in percent correct as our primary measure of perceptually rated accuracy.",
                    "timeFrame": "Before the initiation of treatment and again 5 weeks later."
                }
            ],
            "secondaryOutcomes": [
                {
                    "measure": "Retention of percent correct for the /\u0279/ sound in untreated words, rated by blinded listeners.",
                    "description": "To assess generalization of treatment gains to untreated words, participants will read a word list eliciting /\u0279/. Stimuli in each list will be presented individually in randomized order. Individual words will be isolated from the audio record of each word probe and presented in randomized order for perceptual rating by trained listeners who are blind to treatment condition and time point (but will see the written representation of each target word). We will use the change in percent correct as our primary measure of perceptually rated accuracy. The timeframe of 10 weeks differs from the primary outcome of 5 weeks, and assesses longer-term retention and captures the effects after both groups have received both interventions.",
                    "timeFrame": "Before the initiation of treatment and again 10 weeks later."
                },
                {
                    "measure": "Change in percent correct for the /\u0279/ sound in untreated words, rated by blinded listeners.",
                    "description": "To assess generalization of treatment gains to untreated words, participants will read a word list eliciting /\u0279/. Stimuli in each list will be presented individually in randomized order. Individual words will be isolated from the audio record of each word probe and presented in randomized order for perceptual rating by trained listeners who are blind to treatment condition and time point (but will see the written representation of each target word). We will use the change in percent correct as our primary measure of perceptually rated accuracy. This timeframe compares the rate of improvement with Chaining-AI for the SEQUENTIAL group and the retention after a 5 week break for the CONCURRENT group.",
                    "timeFrame": "After 5 weeks of treatment and again 10 weeks later."
                },
                {
                    "measure": "Survey evaluating impacts of speech disorder on participants' social, emotional, and academic well-being.",
                    "description": "This survey asks parents and participants to report the impact of speech disorder on their child's/their social, emotional, and academic well-being along a 5-point scale. A higher score indicates a greater degree of negative impact of speech disorder on social, emotional, or academic well-being.",
                    "timeFrame": "Before the initiation of treatment and again 5 weeks later."
                },
                {
                    "measure": "Change in percent correct for the /\u0279/ sound in practiced words, rated by blinded listeners.",
                    "description": "Participants will read word list eliciting /\u0279/ in practiced words to assess acquisition. Stimuli in each list will be presented individually in randomized order. Individual words will be isolated from the audio record of each word probe and presented in randomized order for perceptual rating by trained listeners who are blind to treatment condition and time point (but will see the written representation of each target word). We will use the change in percent correct as our primary measure of perceptually rated accuracy.",
                    "timeFrame": "Before the initiation of treatment and again 5 weeks later."
                },
                {
                    "measure": "Change in percent correct for the /\u0279/ sound in practiced words, rated by blinded listeners.",
                    "description": "Participants will read word list eliciting /\u0279/ in practiced words to assess acquisition. Stimuli in each list will be presented individually in randomized order. Individual words will be isolated from the audio record of each word probe and presented in randomized order for perceptual rating by trained listeners who are blind to treatment condition and time point (but will see the written representation of each target word). We will use the change in percent correct as our primary measure of perceptually rated accuracy. The timeframe of 10 weeks captures longer-term retention of practiced words and captures the effects after both groups have received both interventions.",
                    "timeFrame": "Before the initiation of treatment and again 10 weeks later."
                },
                {
                    "measure": "Change in percent correct for the /\u0279/ sound in practiced words, rated by blinded listeners.",
                    "description": "Participants will read word list eliciting /\u0279/ in practiced words to assess acquisition. Stimuli in each list will be presented individually in randomized order. Individual words will be isolated from the audio record of each word probe and presented in randomized order for perceptual rating by trained listeners who are blind to treatment condition and time point (but will see the written representation of each target word). We will use the change in percent correct as our primary measure of perceptually rated accuracy. This timeframe compares the rate of improvement with Chaining-AI for the SEQUENTIAL group and the retention after a 5 week break for the CONCURRENT group.",
                    "timeFrame": "After 5 weeks of treatment and again 10 weeks later."
                }
            ]
        },
        "eligibilityModule": {
            "eligibilityCriteria": "Inclusion Criteria:\n\n* Must speak a rhotic dialect of American English as a dominant language.\n* Must have begun learning English by at least the age of 3 years.\n* Must be between 9;0 to 17;11 years of age.\n* Must have reported difficulty with /\u0279/ production.\n* Must have reported hearing within normal limits.\n* Must receive a Scaled Score of 5 or above on both the Listening Comprehension and Story Retelling subtests from the Test of Integrated Language \\& Literacy Skills (TILLS).\n* Must receive a percentile score of 8 or below on the Goldman-Fristoe Test of Articulation-3 (GFTA-3) Sounds in Words subtest.\n* Must have 1 scorable response with 5+ consecutive correct /pataka/ with \\> 3.4 syllables per second in the MRR-Tri task of the Maximum Performance Tasks OR must demonstrate no childhood apraxia of speech (CAS-only) features in BOTH articulatory and rate/prosody domains of the ProCAD.\n* Must score \\<40% accurate based on word-level items from our /\u0279/ probe list.\n* Must score \\>=15% accuracy on /\u0279/ on 45 syllables following Dynamic Assessment.\n* Must express interest in changing their /\u0279/ production.\n* Must have oral structure and function that are appropriate for /\u0279/ production.\n* Must have access to broadband internet with videoconferencing capabilities\n\nExclusion Criteria:\n\n* Must have no known history of autism spectrum disorder, Down Syndrome, cerebral palsy, intellectual disability, permanent hearing loss, epilepsy/antiepileptic medication, or brain injury/neurosurgery/stroke.\n* Must not have diagnosis of attention deficit disorder, attention deficit hyperactivity disorder, Tourette's, or Obsessive-compulsive disorder.\n* Must have no orthodontic appliances that block the roof of the mouth (e.g., palate expanders).\n* Must not have current cleft palate, fluency disorder, or voice disorder.\n* Must not demonstrate childhood apraxia of speech (CAS-only) features in BOTH articulatory and rate/prosody domains of the ProCAD.",
            "healthyVolunteers": true,
            "sex": "ALL",
            "minimumAge": "9 Years",
            "maximumAge": "17 Years",
            "stdAges": [
                "CHILD"
            ]
        },
        "contactsLocationsModule": {
            "centralContacts": [
                {
                    "name": "Jonathan Preston, PhD",
                    "role": "CONTACT",
                    "phone": "315-443-1351",
                    "email": "jopresto@syr.edu"
                },
                {
                    "name": "Nina Benway, PhD",
                    "role": "CONTACT",
                    "email": "nrbenway@syr.edu"
                }
            ],
            "locations": [
                {
                    "facility": "Syracuse University",
                    "status": "RECRUITING",
                    "city": "Syracuse",
                    "state": "New York",
                    "zip": "13244",
                    "country": "United States",
                    "contacts": [
                        {
                            "name": "Jonathan Preston, PhD",
                            "role": "CONTACT",
                            "phone": "315-443-3143",
                            "email": "jopresto@syr.edu"
                        },
                        {
                            "name": "Nicole Caballero, MS",
                            "role": "CONTACT",
                            "phone": "315-443-1185",
                            "email": "nfcaball@syr.edu"
                        }
                    ],
                    "geoPoint": {
                        "lat": 43.04812,
                        "lon": -76.14742
                    }
                }
            ]
        },
        "referencesModule": {
            "seeAlsoLinks": [
                {
                    "label": "Lab website with recruitment information",
                    "url": "https://speechproductionlab.syr.edu/research/"
                }
            ]
        }
    },
    "derivedSection": {
        "miscInfoModule": {
            "versionHolder": "2024-07-30"
        },
        "conditionBrowseModule": {
            "meshes": [
                {
                    "id": "D000066229",
                    "term": "Speech Sound Disorder"
                }
            ],
            "ancestors": [
                {
                    "id": "D000003147",
                    "term": "Communication Disorders"
                },
                {
                    "id": "D000065886",
                    "term": "Neurodevelopmental Disorders"
                },
                {
                    "id": "D000001523",
                    "term": "Mental Disorders"
                }
            ],
            "browseLeaves": [
                {
                    "id": "M30694",
                    "name": "Speech Sound Disorder",
                    "asFound": "Speech Sound Disorder",
                    "relevance": "HIGH"
                },
                {
                    "id": "M6374",
                    "name": "Communication Disorders",
                    "relevance": "LOW"
                },
                {
                    "id": "M30644",
                    "name": "Neurodevelopmental Disorders",
                    "relevance": "LOW"
                },
                {
                    "id": "M4815",
                    "name": "Mental Disorders",
                    "relevance": "LOW"
                },
                {
                    "id": "M14473",
                    "name": "Psychotic Disorders",
                    "relevance": "LOW"
                }
            ],
            "browseBranches": [
                {
                    "abbrev": "BXM",
                    "name": "Behaviors and Mental Disorders"
                },
                {
                    "abbrev": "All",
                    "name": "All Conditions"
                },
                {
                    "abbrev": "BC10",
                    "name": "Nervous System Diseases"
                },
                {
                    "abbrev": "BC23",
                    "name": "Symptoms and General Pathology"
                }
            ]
        }
    },
    "hasResults": false
}