{
    "protocolSection": {
        "identificationModule": {
            "nctId": "NCT06517225",
            "orgStudyIdInfo": {
                "id": "VISIT non-inferiority"
            },
            "secondaryIdInfos": [
                {
                    "id": "2R01DC017476",
                    "type": "NIH",
                    "link": "https://reporter.nih.gov/quickSearch/2R01DC017476"
                }
            ],
            "organization": {
                "fullName": "New York University",
                "class": "OTHER"
            },
            "briefTitle": "Visual-acoustic Intervention With Service Delivery In-person and Via Telepractice Trial",
            "officialTitle": "Visual-acoustic Intervention With Service Delivery In-person and Via Telepractice (VISIT) Non-Inferiority Trial",
            "acronym": "VISIT",
            "therapeuticArea": [
                "Other"
            ],
            "study": "visual-acoustic-intervention-with-service-delivery-in-person-and-via-telepractice-trial"
        },
        "statusModule": {
            "statusVerifiedDate": "2024-03",
            "overallStatus": "RECRUITING",
            "expandedAccessInfo": {
                "hasExpandedAccess": false
            },
            "startDateStruct": {
                "date": "2024-07-01",
                "type": "ACTUAL"
            },
            "primaryCompletionDateStruct": {
                "date": "2027-12-31",
                "type": "ESTIMATED"
            },
            "completionDateStruct": {
                "date": "2028-07-31",
                "type": "ESTIMATED"
            },
            "studyFirstSubmitDate": "2024-07-18",
            "studyFirstSubmitQcDate": "2024-07-18",
            "studyFirstPostDateStruct": {
                "date": "2024-07-24",
                "type": "ACTUAL"
            },
            "lastUpdateSubmitDate": "2024-07-23",
            "lastUpdatePostDateStruct": {
                "date": "2024-07-25",
                "type": "ACTUAL"
            }
        },
        "sponsorCollaboratorsModule": {
            "responsibleParty": {
                "type": "SPONSOR"
            },
            "leadSponsor": {
                "name": "New York University",
                "class": "OTHER"
            },
            "collaborators": [
                {
                    "name": "Syracuse University",
                    "class": "OTHER"
                },
                {
                    "name": "Montclair State University",
                    "class": "OTHER"
                },
                {
                    "name": "National Institute on Deafness and Other Communication Disorders (NIDCD)",
                    "class": "NIH"
                }
            ]
        },
        "oversightModule": {
            "oversightHasDmc": true,
            "isFdaRegulatedDrug": false,
            "isFdaRegulatedDevice": false
        },
        "descriptionModule": {
            "briefSummary": "Children with speech sound disorder show diminished intelligibility in spoken communication and may thus be perceived as less capable than peers, with negative consequences for both socioemotional and socioeconomic outcomes. New technologies have the potential to transform interventions for speech sound disorder, but there is a lack of rigorous evidence to substantiate this promise. This research will meet a public health need by systematically evaluating the efficacy of visual-acoustic biofeedback intervention delivered in-person versus via telepractice.\n\nThe objective of this study is to test the hypothesis that treatment incorporating visual-acoustic biofeedback can be delivered via telepractice without a significant loss of efficacy. Participants will be randomly assigned to receive identical treatment either via online telepractice or in the laboratory setting. The same software for visual-acoustic biofeedback, staRt, will be used in both conditions. Participants' progress in treatment will be evaluated based on blinded listeners' perceptual ratings of probes produced before and after treatment. Pre and post treatment evaluations will be carried out in person for all participants.",
            "detailedDescription": "This study aims to test the working hypothesis that biofeedback treatment delivery via telepractice will not be associated with a reduction in efficacy that exceeds a maximum acceptable value determined a priori. In a prospective randomized controlled non-inferiority trial, children will be randomly assigned to receive a standard course of visual-acoustic biofeedback intervention delivered in-person or via telepractice. Progress will be measured with blinded listeners' ratings of untreated words produced before and after treatment. A survey will also be administered before and after treatment to assess changes in participants' participation and socio-emotional well-being, as well as participants' and caregivers' satisfaction with the therapy experience."
        },
        "conditionsModule": {
            "conditions": [
                "Speech Sound Disorder"
            ],
            "keywords": [
                "speech",
                "articulation",
                "motor development"
            ]
        },
        "designModule": {
            "studyType": "INTERVENTIONAL",
            "phases": [
                "PHASE2"
            ],
            "designInfo": {
                "allocation": "RANDOMIZED",
                "interventionModel": "PARALLEL",
                "interventionModelDescription": "All participants will complete an initial evaluation to determine eligibility and estimate the severity of speech sound disorder. Participants will be categorized into low and high severity groups and will be randomized with stratification by severity to the in-person or telepractice treatment condition. Participants will then complete 10 weeks of visual-acoustic biofeedback treatment in their randomly assigned condition. Treatment will be delivered individually by a speech-language pathologist and will elicit structured practice of /r/ in 20 semiweekly sessions.",
                "primaryPurpose": "TREATMENT",
                "maskingInfo": {
                    "masking": "SINGLE",
                    "maskingDescription": "All perceptual ratings will be obtained from blinded, naive listeners recruited through online crowdsourcing. Following protocols refined in previous published research, binary rating responses will be aggregated over at least 9 unique listeners per token.",
                    "whoMasked": [
                        "OUTCOMES_ASSESSOR"
                    ]
                }
            },
            "enrollmentInfo": {
                "count": 76,
                "type": "ESTIMATED"
            }
        },
        "armsInterventionsModule": {
            "armGroups": [
                {
                    "label": "Telepractice delivery",
                    "type": "EXPERIMENTAL",
                    "description": "Participants will receive visual-acoustic biofeedback treatment from a clinician in a private, password-protected WebRTC room.",
                    "interventionNames": [
                        "Behavioral: Visual-acoustic biofeedback"
                    ]
                },
                {
                    "label": "In-person delivery",
                    "type": "ACTIVE_COMPARATOR",
                    "description": "Participants will receive visual-acoustic biofeedback treatment from a clinician in a private room in research space at one of the two clinical research sites.",
                    "interventionNames": [
                        "Behavioral: Visual-acoustic biofeedback"
                    ]
                }
            ],
            "interventions": [
                {
                    "type": "BEHAVIORAL",
                    "name": "Visual-acoustic biofeedback",
                    "description": "Behavioral: Visual-acoustic biofeedback In visual-acoustic biofeedback treatment, the elements of traditional treatment (auditory models and verbal descriptions of articulator placement) are enhanced with a dynamic display of the speech signal in the form of the real-time LPC (Linear Predictive Coding) spectrum. The web-based software staRt will be used for intervention delivery.",
                    "armGroupLabels": [
                        "In-person delivery",
                        "Telepractice delivery"
                    ],
                    "otherNames": [
                        "staRt app"
                    ]
                }
            ]
        },
        "outcomesModule": {
            "primaryOutcomes": [
                {
                    "measure": "Percentage of \"Correct\" Ratings by Blinded Untrained Listeners for /r/ Sounds Produced in Word Probes",
                    "description": "To assess generalization of treatment gains to untreated words, participants will be assessed with standard probes (30 words \\[considered the primary target\\], 20 syllables, and 10 sentences containing /r/ in various phonetic contexts). Stimuli in each probe will be presented individually in randomized order with blocking by stimulus type (word, syllable, sentence). Individual words will be isolated from the audio record of each word probe and presented in randomized order for binary rating (correct/incorrect) by 9 untrained listeners who are blind to treatment condition and time point, but will see the written representation of each target word. The proportion of \"correct\" ratings for each token will be used as the primary measure of perceptually rated accuracy.",
                    "timeFrame": "Before the initiation of treatment and again after the end of all treatment (10 weeks later)"
                }
            ],
            "secondaryOutcomes": [
                {
                    "measure": "1. Survey evaluating impacts of speech disorder on participants' social, emotional, and academic well-being.",
                    "description": "This survey asks participants to report the impact of speech disorder on their child's social, emotional, and academic well-being. Parents are asked to circle a number from 1 to 5. For all questions, a higher score indicates a greater degree of negative impact of speech disorder on social, emotional, or academic well-being. An impact score will be calculated as described in a previous published study (Hitchcock, Harel, \\& McAllister Byun, 2015).",
                    "timeFrame": "Before the initiation of treatment and again after the end of all treatment (10 weeks later)"
                }
            ]
        },
        "eligibilityModule": {
            "eligibilityCriteria": "Inclusion Criteria:\n\n* Must be between 9;0 and 17;11 (years;months) old at the time of enrollment.\n* Must speak English as the dominant or equally dominant language\n* Must have begun learning English by age 3, per parent report.\n* Must hear a rhotic dialect of English from at least one speaker in the home if the home language is English.\n* Must pass a pure-tone hearing screening.\n* Must pass a brief examination of oral structure and function.\n* Must exhibit less than thirty percent accuracy, based on trained listener ratings, on a probe list eliciting /r/ in various phonetic contexts at the word level.\n* Must demonstrate age-appropriate receptive and expressive language abilities on the Clinical Evaluation of Language Fundamentals-5 (CELF-5).\n* Must have access to a laptop or desktop computer for study sessions in the event of randomization to the telepractice condition.\n* Must have home wifi sufficient to support video calls in the event of randomization to the telepractice condition.\n\nExclusion Criteria:\n\n* Must not exhibit voice or fluency disorder of a severity judged likely to interfere with the ability to participate in study activities.\n* Must not currently have orthodontia that crosses the palate and cannot be removed.\n* Must not have history of permanent hearing loss.\n* Must not have an existing diagnosis of developmental disability such as cerebral palsy or Down Syndrome.\n* Must not have history of major brain injury, surgery, or stroke in the past year.\n* Must not have epilepsy with active seizure incidents with in the past 6 months.\n* Must not show clinically significant signs of apraxia of speech or dysarthria.",
            "healthyVolunteers": false,
            "sex": "FEMALE",
            "minimumAge": "9 Years",
            "maximumAge": "17 Years",
            "stdAges": [
                "CHILD"
            ]
        },
        "contactsLocationsModule": {
            "locations": [
                {
                    "facility": "Montclair State University",
                    "status": "RECRUITING",
                    "city": "Bloomfield",
                    "state": "New Jersey",
                    "zip": "07003",
                    "country": "United States",
                    "contacts": [
                        {
                            "name": "Elaine R Hitchcock, PhD",
                            "role": "CONTACT",
                            "phone": "973-229-3797",
                            "email": "hitchcocke@montclair.edu"
                        },
                        {
                            "name": "Laura C Ochs, MS",
                            "role": "CONTACT",
                            "phone": "(619) 784-4979",
                            "email": "ochsl@montclair.edu"
                        }
                    ],
                    "geoPoint": {
                        "lat": 40.80677,
                        "lon": -74.18542
                    }
                },
                {
                    "facility": "New York University",
                    "status": "ACTIVE_NOT_RECRUITING",
                    "city": "New York",
                    "state": "New York",
                    "zip": "10012",
                    "country": "United States",
                    "geoPoint": {
                        "lat": 40.71427,
                        "lon": -74.00597
                    }
                },
                {
                    "facility": "Syracuse University",
                    "status": "RECRUITING",
                    "city": "Syracuse",
                    "state": "New York",
                    "zip": "13244",
                    "country": "United States",
                    "contacts": [
                        {
                            "name": "Jonathan L Preston, PhD",
                            "role": "CONTACT",
                            "phone": "315-443-3143",
                            "email": "jopresto@syr.edu"
                        },
                        {
                            "name": "Megan Leece, MS",
                            "role": "CONTACT",
                            "phone": "315-443-1351",
                            "email": "mcleece@syr.edu"
                        }
                    ],
                    "geoPoint": {
                        "lat": 43.04812,
                        "lon": -76.14742
                    }
                }
            ]
        },
        "referencesModule": {
            "references": [
                {
                    "pmid": "36930986",
                    "type": "BACKGROUND",
                    "citation": "Ayala SA, Eads A, Kabakoff H, Swartz MT, Shiller DM, Hill J, Hitchcock ER, Preston JL, McAllister T. Auditory and Somatosensory Development for Speech in Later Childhood. J Speech Lang Hear Res. 2023 Apr 12;66(4):1252-1273. doi: 10.1044/2022_JSLHR-22-00496. Epub 2023 Mar 17."
                },
                {
                    "pmid": "37319018",
                    "type": "BACKGROUND",
                    "citation": "Benway NR, Preston JL, Hitchcock E, Rose Y, Salekin A, Liang W, McAllister T. Reproducible Speech Research With the Artificial Intelligence-Ready PERCEPT Corpora. J Speech Lang Hear Res. 2023 Jun 20;66(6):1986-2009. doi: 10.1044/2023_JSLHR-22-00343. Epub 2023 Jun 15."
                },
                {
                    "pmid": "28795872",
                    "type": "BACKGROUND",
                    "citation": "Campbell H, Harel D, Hitchcock E, McAllister Byun T. Selecting an acoustic correlate for automated measurement of American English rhotic production in children. Int J Speech Lang Pathol. 2018 Nov;20(6):635-643. doi: 10.1080/17549507.2017.1359334. Epub 2017 Aug 10."
                },
                {
                    "pmid": "28703653",
                    "type": "BACKGROUND",
                    "citation": "Campbell H, McAllister Byun T. Deriving individualised /r/ targets from the acoustics of children's non-rhotic vowels. Clin Linguist Phon. 2018;32(1):70-87. doi: 10.1080/02699206.2017.1330898. Epub 2017 Jul 13."
                },
                {
                    "pmid": "27267258",
                    "type": "BACKGROUND",
                    "citation": "Harel D, Hitchcock ER, Szeredi D, Ortiz J, McAllister Byun T. Finding the experts in the crowd: Validity and reliability of crowdsourced measures of children's gradient speech contrasts. Clin Linguist Phon. 2017;31(1):104-117. doi: 10.3109/02699206.2016.1174306. Epub 2016 Jun 7."
                },
                {
                    "pmid": "36623212",
                    "type": "BACKGROUND",
                    "citation": "Hitchcock ER, Ochs LC, Swartz MT, Leece MC, Preston JL, McAllister T. Tutorial: Using Visual-Acoustic Biofeedback for Speech Sound Training. Am J Speech Lang Pathol. 2023 Jan 11;32(1):18-36. doi: 10.1044/2022_AJSLP-22-00142. Epub 2023 Jan 9."
                },
                {
                    "pmid": "26458203",
                    "type": "BACKGROUND",
                    "citation": "Hitchcock ER, Harel D, Byun TM. Social, Emotional, and Academic Impact of Residual Speech Errors in School-Aged Children: A Survey Study. Semin Speech Lang. 2015 Nov;36(4):283-94. doi: 10.1055/s-0035-1562911. Epub 2015 Oct 12."
                },
                {
                    "pmid": "25216375",
                    "type": "BACKGROUND",
                    "citation": "Hitchcock ER, Byun TM. Enhancing generalisation in biofeedback intervention using the challenge point framework: a case study. Clin Linguist Phon. 2015 Jan;29(1):59-75. doi: 10.3109/02699206.2014.956232. Epub 2014 Sep 12."
                },
                {
                    "pmid": "28389677",
                    "type": "BACKGROUND",
                    "citation": "McAllister Byun T. Efficacy of Visual-Acoustic Biofeedback Intervention for Residual Rhotic Errors: A Single-Subject Randomization Study. J Speech Lang Hear Res. 2017 May 24;60(5):1175-1193. doi: 10.1044/2016_JSLHR-S-16-0038."
                },
                {
                    "pmid": "27891084",
                    "type": "BACKGROUND",
                    "citation": "McAllister Byun T, Campbell H. Differential Effects of Visual-Acoustic Biofeedback Intervention for Residual Speech Errors. Front Hum Neurosci. 2016 Nov 11;10:567. doi: 10.3389/fnhum.2016.00567. eCollection 2016."
                },
                {
                    "pmid": "25578293",
                    "type": "BACKGROUND",
                    "citation": "McAllister Byun T, Halpin PF, Szeredi D. Online crowdsourcing for efficient rating of speech: a validation study. J Commun Disord. 2015 Jan-Feb;53:70-83. doi: 10.1016/j.jcomdis.2014.11.003. Epub 2014 Dec 15."
                },
                {
                    "pmid": "25088034",
                    "type": "BACKGROUND",
                    "citation": "Byun TM, Hitchcock ER, Swartz MT. Retroflex versus bunched in treatment for rhotic misarticulation: evidence from ultrasound biofeedback intervention. J Speech Lang Hear Res. 2014 Dec;57(6):2116-30. doi: 10.1044/2014_JSLHR-S-14-0034."
                },
                {
                    "pmid": "22442281",
                    "type": "BACKGROUND",
                    "citation": "Byun TM, Hitchcock ER. Investigating the use of traditional and spectral biofeedback approaches to intervention for /r/ misarticulation. Am J Speech Lang Pathol. 2012 Aug;21(3):207-21. doi: 10.1044/1058-0360(2012/11-0083). Epub 2012 Mar 21."
                },
                {
                    "pmid": "35050705",
                    "type": "BACKGROUND",
                    "citation": "Peterson L, Savarese C, Campbell T, Ma Z, Simpson KO, McAllister T. Telepractice Treatment of Residual Rhotic Errors Using App-Based Biofeedback: A Pilot Study. Lang Speech Hear Serv Sch. 2022 Apr 11;53(2):256-274. doi: 10.1044/2021_LSHSS-21-00084. Epub 2022 Jan 20."
                },
                {
                    "pmid": "30073249",
                    "type": "BACKGROUND",
                    "citation": "Preston JL, McAllister T, Phillips E, Boyce S, Tiede M, Kim JS, Whalen DH. Treatment for Residual Rhotic Errors With High- and Low-Frequency Ultrasound Visual Feedback: A Single-Case Experimental Design. J Speech Lang Hear Res. 2018 Aug 8;61(8):1875-1892. doi: 10.1044/2018_JSLHR-S-17-0441."
                },
                {
                    "pmid": "29546269",
                    "type": "BACKGROUND",
                    "citation": "Preston JL, Holliman-Lopez G, Leece MC. Do Participants Report Any Undesired Effects in Ultrasound Speech Therapy? Am J Speech Lang Pathol. 2018 May 3;27(2):813-818. doi: 10.1044/2017_AJSLP-17-0121."
                },
                {
                    "pmid": "28117824",
                    "type": "BACKGROUND",
                    "citation": "Preston JL, McAllister Byun T, Boyce SE, Hamilton S, Tiede M, Phillips E, Rivera-Campos A, Whalen DH. Ultrasound Images of the Tongue: A Tutorial for Assessment and Remediation of Speech Sound Errors. J Vis Exp. 2017 Jan 3;(119):55123. doi: 10.3791/55123."
                }
            ]
        },
        "ipdSharingStatementModule": {
            "ipdSharing": "YES",
            "description": "A manual of procedures and materials for treatment and clinician training will be released through the Open Science Framework (OSF). Complete de-identified data and analysis scripts on OSF will also be released when the study is completed.\n\nOSF as projects are completed",
            "infoTypes": [
                "STUDY_PROTOCOL",
                "ANALYTIC_CODE"
            ],
            "timeFrame": "Data will be shared within 6 months of the study end date (7/31/28) and will be made available indefinitely.",
            "accessCriteria": "Publicly accessible",
            "url": "http://osf.io"
        }
    },
    "derivedSection": {
        "miscInfoModule": {
            "versionHolder": "2024-07-30"
        },
        "conditionBrowseModule": {
            "meshes": [
                {
                    "id": "D000066229",
                    "term": "Speech Sound Disorder"
                }
            ],
            "ancestors": [
                {
                    "id": "D000003147",
                    "term": "Communication Disorders"
                },
                {
                    "id": "D000065886",
                    "term": "Neurodevelopmental Disorders"
                },
                {
                    "id": "D000001523",
                    "term": "Mental Disorders"
                }
            ],
            "browseLeaves": [
                {
                    "id": "M30694",
                    "name": "Speech Sound Disorder",
                    "asFound": "Speech Sound Disorder",
                    "relevance": "HIGH"
                },
                {
                    "id": "M6374",
                    "name": "Communication Disorders",
                    "relevance": "LOW"
                },
                {
                    "id": "M30644",
                    "name": "Neurodevelopmental Disorders",
                    "relevance": "LOW"
                },
                {
                    "id": "M4815",
                    "name": "Mental Disorders",
                    "relevance": "LOW"
                },
                {
                    "id": "M14473",
                    "name": "Psychotic Disorders",
                    "relevance": "LOW"
                }
            ],
            "browseBranches": [
                {
                    "abbrev": "BXM",
                    "name": "Behaviors and Mental Disorders"
                },
                {
                    "abbrev": "All",
                    "name": "All Conditions"
                },
                {
                    "abbrev": "BC10",
                    "name": "Nervous System Diseases"
                },
                {
                    "abbrev": "BC23",
                    "name": "Symptoms and General Pathology"
                }
            ]
        }
    },
    "hasResults": false
}