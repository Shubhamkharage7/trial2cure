{
    "protocolSection": {
        "identificationModule": {
            "nctId": "NCT05668923",
            "orgStudyIdInfo": {
                "id": "STUDY21120103"
            },
            "secondaryIdInfos": [
                {
                    "id": "1R01DC019904-01",
                    "type": "NIH",
                    "link": "https://reporter.nih.gov/quickSearch/1R01DC019904-01"
                }
            ],
            "organization": {
                "fullName": "University of Pittsburgh",
                "class": "OTHER"
            },
            "briefTitle": "Speech Signals in Stuttering",
            "officialTitle": "Neural Processing of Speech Signals in Children Who Stutter",
            "therapeuticArea": [
                "Pediatrics"
            ],
            "study": "speech-signals-in-stuttering"
        },
        "statusModule": {
            "statusVerifiedDate": "2023-11",
            "overallStatus": "RECRUITING",
            "expandedAccessInfo": {
                "hasExpandedAccess": false
            },
            "startDateStruct": {
                "date": "2022-09-21",
                "type": "ACTUAL"
            },
            "primaryCompletionDateStruct": {
                "date": "2027-12",
                "type": "ESTIMATED"
            },
            "completionDateStruct": {
                "date": "2027-12",
                "type": "ESTIMATED"
            },
            "studyFirstSubmitDate": "2022-12-02",
            "studyFirstSubmitQcDate": "2022-12-25",
            "studyFirstPostDateStruct": {
                "date": "2022-12-30",
                "type": "ACTUAL"
            },
            "lastUpdateSubmitDate": "2023-11-02",
            "lastUpdatePostDateStruct": {
                "date": "2023-11-03",
                "type": "ACTUAL"
            }
        },
        "sponsorCollaboratorsModule": {
            "responsibleParty": {
                "type": "PRINCIPAL_INVESTIGATOR",
                "investigatorFullName": "Amanda Hampton Wray",
                "investigatorTitle": "Assistant Professor",
                "investigatorAffiliation": "University of Pittsburgh"
            },
            "leadSponsor": {
                "name": "University of Pittsburgh",
                "class": "OTHER"
            },
            "collaborators": [
                {
                    "name": "University of Michigan",
                    "class": "OTHER"
                },
                {
                    "name": "National Institute on Deafness and Other Communication Disorders (NIDCD)",
                    "class": "NIH"
                }
            ]
        },
        "oversightModule": {
            "isFdaRegulatedDrug": false,
            "isFdaRegulatedDevice": false
        },
        "descriptionModule": {
            "briefSummary": "The purpose of this research study is to understand how speech and language are processed in the brain. This study will provide information that may help with the understanding how speech and language are processed in children and whether there may be differences between children who stutter and children who do not stutter. This project will evaluate these neural processes for speech signals in children who stutter and control subjects through a battery of behavioral speech and language tests, electroencephalography-based (EEG) tasks, functional magnetic resonance imaging (fMRI), and computational modeling.",
            "detailedDescription": "The study will evaluate the integrity of neural processes underlying speech sound encoding and the ways in which these processes are modulated by task demands using neuroimaging and computational modeling.\n\nAge-appropriate standardized tests for assessing speech, language, and cognitive skills will be administered by a certified speech language pathologist or trained lab member.\n\nThe investigators will also measure electroencephalography (EEG) via frequency following responses (FFRs) and temporal response functions (TRFs) while children complete speech-sound tasks of varying difficulty including syllable listening and identification and continuous speech narrative comprehension tasks. Both tasks will be presented in both quiet and in background noise. EEG signals will be collected using Ag-AgCl scalp electrodes, and responses will be recorded at a sampling rate of 25 kHz using Brain Vision Recorder (Brain Products, Gilching, Germany).\n\nThe investigators will also leverage functional MRI (fMRI) to assess multiple neural systems underlying speech sound processing in children who stutter in a 3T scanner. Employing similar speech-sound tasks in the same participants as the EEG tasks will allow for quantifying neural activations and representations in auditory, speech motor articulatory, and attention networks during simple and complex speech tasks. A series of MRI scans will be recorded to provide data regarding the participant's brain anatomy. These scans will be analyzed on their own and also used in combination with functional scans. All participants will be screened for metal and other objects that are not appropriate for the MRI scanner room. Participants will be given earplugs and/or headphones to wear."
        },
        "conditionsModule": {
            "conditions": [
                "Stuttering, Childhood"
            ]
        },
        "designModule": {
            "studyType": "INTERVENTIONAL",
            "phases": [
                "NA"
            ],
            "designInfo": {
                "allocation": "NA",
                "interventionModel": "SINGLE_GROUP",
                "primaryPurpose": "BASIC_SCIENCE",
                "maskingInfo": {
                    "masking": "NONE"
                }
            },
            "enrollmentInfo": {
                "count": 600,
                "type": "ESTIMATED"
            }
        },
        "armsInterventionsModule": {
            "armGroups": [
                {
                    "label": "Speech sound stimulation",
                    "type": "EXPERIMENTAL",
                    "description": "Speech sound stimulation via behavioral, electrophysiological, and magnetic resonance imaging-based tasks",
                    "interventionNames": [
                        "Behavioral: Speech sound stimulation"
                    ]
                }
            ],
            "interventions": [
                {
                    "type": "BEHAVIORAL",
                    "name": "Speech sound stimulation",
                    "description": "Behavioral-, electrophysiological-, and magnetic resonance imaging-based speech sound testing",
                    "armGroupLabels": [
                        "Speech sound stimulation"
                    ]
                }
            ]
        },
        "outcomesModule": {
            "primaryOutcomes": [
                {
                    "measure": "Speech Sound Identification",
                    "description": "Behavioral responses will be measured for the syllable identification task in quiet and in the presence of background noise. Children will respond as quickly as possible to identify which speech sound they heard. Within and between group analyses will be conducted between children who stutter and control subjects. Drift diffusion models (DDMs) will be used to aggregate the behavioral responses of accuracy and reaction time to evaluate bias toward more accurate or faster responses as well as change in response behaviors over time in each group.",
                    "timeFrame": "1 Session (up to 2 hours)"
                },
                {
                    "measure": "Frequency Following Responses (EEG)",
                    "description": "Frequency following responses (FFRs) will be collected and used to quantify neural encoding of fast temporal cues in auditory stimuli, including speech sounds. FFRs (70-1500 Hz) will be elicited by syllables. FFRs will be elicited in quiet conditions and in the presence of a competing background story. FFRs will be measured for magnitude. Decoding of FFRs elicited by syllables using support vector machine classifiers will be analyzed. Within and between group analyses will be conducted between children who stutter and control subjects.",
                    "timeFrame": "1 Session (up to 30 minutes)"
                },
                {
                    "measure": "Temporal Response Functions (EEG)",
                    "description": "Temporal response function (TRFs) analysis directly compares a continuously varying stimulus, such as continuous speech, to EEG data. The relationship between the continuous speech and EEG signals will be estimated as a continuous wave describing how a change in a continuous speech feature relates to changes in the EEG signal. The EEG data predicted by the TRF are compared to the real, observed EEG data via correlation, resulting in a measure of fitness (Pearson's r) for how well the stimulus explains the observed neural activity. Multivariate linear ridge regression using leave-one-out-cross validation method, to prevent over-fitting the data, will be utilized to compare the predicted and obtained EEG. Higher correlations between the predicted and obtained EEG reflect better cortical encoding of the speech envelope. Within and between group analyses will be conducted between children who stutter and control subjects.",
                    "timeFrame": "1 Session (up to 1 hour)"
                },
                {
                    "measure": "Blood-oxygen level dependent activation (functional magnetic resonance imaging)",
                    "description": "Brain activation patterns indexed by blood-oxygen level dependent (BOLD) fMRI signals will be analyzed. BOLD responses will be estimated separately for each participant for each functional task. Study-level outcomes include main effects of group (children who stutter vs. controls), group by region interactions, and group by network (auditory, speech motor, and attention) interactions. Drift diffusion models (DDMs) will be used to aggregate the behavioral responses of accuracy and reaction time (e.g. during the categorization the sounds such as /ba/ or /da/) to evaluate bias toward more accurate or faster responses as well as change in response behaviors over time in each group.",
                    "timeFrame": "1 Session (up to 2 hours)"
                },
                {
                    "measure": "Multi-voxel pattern analysis (functional magnetic resonance imaging)",
                    "description": "Multi-voxel pattern analysis (MVPA) is a machine learning analysis technique that aims to quantify spatially distributed neural representations across ensembles of voxels. MVPA will be used to determine the neural activity patterns that contain predictive information about the syllables (e.g. /ba/, da/) in the tasks in quiet and with background noise. Extracted BOLD parameter estimates for each syllable will be entered into the analysis. Participant specific classification cross-validation accuracies (per pre-determined regions of interest) will be contrasted between conditions to determine regions of interest in which representations are enhanced or degraded by increasing task demands. Regions with significant group-level classification accuracies in each task, as well as regions of interest showing task-dependent changes in classification accuracies, will be established by permutation testing for each region of interest for each participant.",
                    "timeFrame": "1 Session (up to 2 hours)"
                },
                {
                    "measure": "Psychophysiological Interactions",
                    "description": "Psychophysiological interaction (PPI) analyses evaluate task-dependent interactions between brain regions. Each pre-determined region of interest will serve as a seed region. For each target region (all other regions of interest), a general linear model will be used to estimate the interaction of task-related hemodynamic effects and the effects that are linearly related to the time-series of the seed region. Significant interactions reflect regions for which the effective connectivity with the seed-region changes as a function of task condition (i.e., indicating regions that are preferentially coupled for a specific task). Study-level outcomes will assess main effects of group (children who stutter vs controls), group by region interactions, and group by network (auditory, speech motor, attention) interactions.",
                    "timeFrame": "1 Session (up to 2 hours)"
                }
            ]
        },
        "eligibilityModule": {
            "eligibilityCriteria": "Inclusion Criteria:\n\n* Speaks English as primary language\n* Language abilities within the typical range\n* Cognitive abilities within the typical range\n* No contraindications for MRI\n\nInclusion criteria for children who stutter:\n\n* Presence of developmental stuttering (onset in childhood)\n* No history of other communication disorder\n\nInclusion criteria for children who do not stutter:\n\n* No family history of stuttering\n* No history of other communication disorders (e.g., hearing impairment, language impairment, cognitive impairment/injury)\n\nExclusion Criteria:\n\n* Taking medication that alters neural function\n* Cognitive skills below the typical range\n* Major medical illness\n* Not a fluent speaker of English\n* Pregnant or possibly pregnant\n* Metal implants in your body (including pacemakers, neurostimulators, or other metal objects)\n* Shrapnel injuries\n* Ocular foreign bodies (e.g., metal shavings)\n* Metal piercings that cannot be removed for the scan\n* Tattoos containing iron or metal pigments\n* Prone to claustrophobia\n* For fMRI, those with head circumference greater than 60cm or whose weight is more than 300 pounds will be excluded due to the size of the fMRI magnet bore",
            "healthyVolunteers": true,
            "sex": "ALL",
            "minimumAge": "5 Years",
            "maximumAge": "17 Years",
            "stdAges": [
                "CHILD"
            ]
        },
        "contactsLocationsModule": {
            "centralContacts": [
                {
                    "name": "Brittany Coleman, MS, CCC-SLP",
                    "role": "CONTACT",
                    "phone": "412-710-6028",
                    "email": "bmc162@pitt.edu"
                },
                {
                    "name": "Ashley Parker, PhD",
                    "role": "CONTACT",
                    "phone": "412-710-6028",
                    "email": "ashley.parker@pitt.edu"
                }
            ],
            "overallOfficials": [
                {
                    "name": "Amanda Hampton Wray, PhD, CCC-SLP",
                    "affiliation": "University of Pittsburgh",
                    "role": "PRINCIPAL_INVESTIGATOR"
                }
            ],
            "locations": [
                {
                    "facility": "University of Michigan",
                    "status": "NOT_YET_RECRUITING",
                    "city": "Ann Arbor",
                    "state": "Michigan",
                    "zip": "48105",
                    "country": "United States",
                    "contacts": [
                        {
                            "name": "Emily Garnett, PhD, CCC-SLP",
                            "role": "CONTACT",
                            "email": "emilyog@med.umich.edu"
                        },
                        {
                            "name": "Soo-Eun Chang, PhD, CCC-SLP",
                            "role": "PRINCIPAL_INVESTIGATOR"
                        }
                    ],
                    "geoPoint": {
                        "lat": 42.27756,
                        "lon": -83.74088
                    }
                },
                {
                    "facility": "University of Pittsburgh",
                    "status": "RECRUITING",
                    "city": "Pittsburgh",
                    "state": "Pennsylvania",
                    "zip": "15213",
                    "country": "United States",
                    "contacts": [
                        {
                            "name": "Brittany Coleman, MS, CCC-SLP",
                            "role": "CONTACT",
                            "phone": "412-710-6028",
                            "email": "bmc162@pitt.edu"
                        },
                        {
                            "name": "Amanda Hampton Wray, PhD, CCC-SLP",
                            "role": "PRINCIPAL_INVESTIGATOR"
                        }
                    ],
                    "geoPoint": {
                        "lat": 40.44062,
                        "lon": -79.99589
                    }
                }
            ]
        },
        "ipdSharingStatementModule": {
            "ipdSharing": "YES",
            "description": "The investigators will follow the guidelines set forth by the Open Knowledge International, which is a global non-profit organization that advocates for open science and open data. Our objectives in data sharing are to provide free and open access to everyone, make data easily available in a format that is broadly accessible and ensures longevity.",
            "infoTypes": [
                "STUDY_PROTOCOL",
                "SAP",
                "ANALYTIC_CODE"
            ],
            "timeFrame": "Data will become available as soon as possible but no later than one year upon completion of the study",
            "accessCriteria": "Our data will be made publicly available as soon as possible online to make it easily and widely accessible."
        }
    },
    "derivedSection": {
        "miscInfoModule": {
            "versionHolder": "2024-07-30"
        },
        "conditionBrowseModule": {
            "meshes": [
                {
                    "id": "D000013342",
                    "term": "Stuttering"
                }
            ],
            "ancestors": [
                {
                    "id": "D000013064",
                    "term": "Speech Disorders"
                },
                {
                    "id": "D000007806",
                    "term": "Language Disorders"
                },
                {
                    "id": "D000003147",
                    "term": "Communication Disorders"
                },
                {
                    "id": "D000019954",
                    "term": "Neurobehavioral Manifestations"
                },
                {
                    "id": "D000009461",
                    "term": "Neurologic Manifestations"
                },
                {
                    "id": "D000009422",
                    "term": "Nervous System Diseases"
                }
            ],
            "browseLeaves": [
                {
                    "id": "M16132",
                    "name": "Stuttering",
                    "asFound": "Stuttering",
                    "relevance": "HIGH"
                },
                {
                    "id": "M15864",
                    "name": "Speech Disorders",
                    "relevance": "LOW"
                },
                {
                    "id": "M10823",
                    "name": "Language Disorders",
                    "relevance": "LOW"
                },
                {
                    "id": "M6374",
                    "name": "Communication Disorders",
                    "relevance": "LOW"
                },
                {
                    "id": "M21826",
                    "name": "Neurobehavioral Manifestations",
                    "relevance": "LOW"
                },
                {
                    "id": "M12404",
                    "name": "Neurologic Manifestations",
                    "relevance": "LOW"
                }
            ],
            "browseBranches": [
                {
                    "abbrev": "BC10",
                    "name": "Nervous System Diseases"
                },
                {
                    "abbrev": "BC23",
                    "name": "Symptoms and General Pathology"
                },
                {
                    "abbrev": "All",
                    "name": "All Conditions"
                },
                {
                    "abbrev": "BXM",
                    "name": "Behaviors and Mental Disorders"
                }
            ]
        }
    },
    "hasResults": false
}